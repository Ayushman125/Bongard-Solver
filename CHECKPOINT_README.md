# System 1 Training with Checkpointing

This document describes the new checkpoint-enabled training system that avoids redundant operations for data generation, model training, and evaluation.

## ğŸš€ Quick Start

### Professional Training (Recommended)
```bash
# Run complete professional training pipeline
python -m scripts.validate_phase1

# Check checkpoint status
python train_system1_checkpointed.py --status

# Force retrain everything
python train_system1_checkpointed.py --professional --force-all
```

### Standard Training
```bash
# Basic training with checkpointing
python train_system1_checkpointed.py --epochs 25 --batch_size 8

# Force specific operations
python train_system1_checkpointed.py --force-data --epochs 10
python train_system1_checkpointed.py --force-train --epochs 50
```

## ğŸ—ï¸ Architecture

### Checkpoint System Components

1. **CheckpointManager** (`utils/checkpointing.py`)
   - Tracks completion of data generation, training, evaluation
   - Stores metadata about configurations and results
   - Validates checkpoint integrity

2. **ProfessionalTrainingPipeline** (`utils/professional_training.py`)
   - Integrates checkpointing with training pipeline
   - Professional-grade configuration
   - Comprehensive logging and result tracking

3. **Checkpoint Files**
   ```
   checkpoints/
   â”œâ”€â”€ data_generation.json    # Synthetic data status
   â”œâ”€â”€ training.json          # Model training status  
   â””â”€â”€ evaluation.json        # Evaluation results status
   ```

### Professional Training Configuration

The professional training uses optimized parameters:
- **Dataset**: 10,000 synthetic images (416x416 resolution)
- **Model**: ResNet-50 backbone (vs ResNet-18 standard)
- **Training**: 50 epochs, OneCycleLR scheduler, SWA
- **Evaluation**: COCO metrics on synthetic + real datasets

## ğŸ“‹ Checkpoint States

### Data Generation
- **Tracks**: Dataset size, image size, configuration hash
- **Validates**: Output directory exists, annotation count
- **Triggers Reset**: If output directory missing

### Model Training  
- **Tracks**: Configuration hash, best checkpoint path, metrics
- **Validates**: Checkpoint file exists and loads
- **Triggers Reset**: If checkpoint file missing or corrupted

### Model Evaluation
- **Tracks**: Model checkpoint, evaluation configuration, metrics  
- **Validates**: Referenced model checkpoint exists
- **Triggers Reset**: If model checkpoint missing

## ğŸ¯ Performance Targets

The system tracks achievement of these performance targets:

| Dataset | Metric | Target | Status |
|---------|--------|--------|---------|
| Synthetic | AP@0.5:0.95 | â‰¥ 0.85 | ğŸ¯ |
| Synthetic | AP@0.5 | â‰¥ 0.95 | ğŸ¯ |
| Real Bongard-LOGO | AP@0.5 | â‰¥ 0.70 | âœ… |

## ğŸ“ Directory Structure

```
BongordSolver/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ checkpointing.py           # Checkpoint management
â”‚   â””â”€â”€ professional_training.py   # Professional training pipeline
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ validate_phase1.py         # Main validation script
â”œâ”€â”€ checkpoints/                   # Checkpoint status files
â”œâ”€â”€ processed_data/                # Generated synthetic data
â”‚   â””â”€â”€ professional_synthetic/    # Professional training data
â”œâ”€â”€ results/                       # Training results and metrics
â””â”€â”€ logs/                         # Training and validation logs
```

## ğŸ”§ Usage Examples

### Check Status
```bash
python train_system1_checkpointed.py --status
```
Output:
```
ğŸ” Checkpoint Status:
   Data Generation: âœ… 2025-01-19 10:30:15
   Training: âœ… 2025-01-19 12:45:22
   Evaluation: âœ… 2025-01-19 13:15:30
```

### Reset Specific Stages
```bash
# Reset only data generation
python train_system1_checkpointed.py --reset data

# Reset all checkpoints
python train_system1_checkpointed.py --reset all
```

### Professional Training with Custom Parameters
```bash
python train_system1_checkpointed.py --professional \
    --dataset_size 15000 \
    --epochs 75 \
    --batch_size 12
```

## ğŸ“Š Results and Logging

### Result Files
- **Professional Training**: `results/professional_training_results_YYYYMMDD_HHMMSS.json`
- **Standard Training**: `results/system1_training_results.json`

### Log Files
- **Main Training**: `logs/professional_training.log`
- **Phase 1 Validation**: `logs/validate_phase1.log`

### Metrics Tracked
- Training loss and validation metrics per epoch
- COCO detection metrics (AP@0.5, AP@0.75, AP@0.5:0.95)
- Performance target achievement status
- Training time and resource usage

## ğŸš¨ Troubleshooting

### Common Issues

1. **Checkpoint Validation Failures**
   ```bash
   # Check and reset corrupted checkpoints
   python train_system1_checkpointed.py --status
   python train_system1_checkpointed.py --reset all
   ```

2. **Memory Issues**
   ```bash
   # Reduce batch size for limited GPU memory
   python train_system1_checkpointed.py --professional --batch_size 8
   ```

3. **Force Complete Retrain**
   ```bash
   # Ignore all checkpoints and start fresh
   python train_system1_checkpointed.py --professional --force-all
   ```

### Performance Optimization

1. **GPU Utilization**: Monitor with `nvidia-smi`
2. **Batch Size**: Adjust based on GPU memory (8-16 typical)
3. **Mixed Precision**: Enabled by default in professional mode
4. **Data Loading**: 4-6 workers optimal for most systems

## ğŸ”„ Integration with Existing Code

The checkpoint system is designed to integrate seamlessly:

1. **Backwards Compatible**: Existing scripts continue to work
2. **Optional Checkpointing**: Can be enabled/disabled per run  
3. **Modular Design**: Components can be used independently
4. **Configuration Hashing**: Automatic detection of configuration changes

## ğŸ“ˆ Next Steps

With checkpointing in place, you can now:

1. **Scale Training**: Safely experiment with larger datasets and longer training
2. **Hyperparameter Tuning**: Efficiently test different configurations  
3. **Incremental Development**: Make code changes without losing training progress
4. **Production Deployment**: Use professional training for final model training

The system is ready for serious model development and experimentation! ğŸ‰
